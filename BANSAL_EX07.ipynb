{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Machine Learning Lab: Exercise Sheet 7</center>\n",
    "<center> <b>Submitted By: Mohit Bansal</b></center>\n",
    "<center> <b>Student ID: 279314</b></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets\n",
    "1. Classification Datasets: You can use one of the two datasets (or optionally, both datasets):\n",
    "\n",
    "    (a) **Iris dataset D1**: Target attribute class: Iris Setosa, Iris Versicolour, Iris Virginica https://archive.ics.uci.edu/ml/datasets/Iris\n",
    "\n",
    "    (b) **Wine Quality D2**: (use winequality-red.csv) http://archive.ics.uci.edu/ml/datasets/Wine+Quality\n",
    "    \n",
    "You are required to pre-process given datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal-length</th>\n",
       "      <th>sepal-width</th>\n",
       "      <th>petal-length</th>\n",
       "      <th>petal-width</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal-length  sepal-width  petal-length  petal-width       class \n",
       "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
       "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
       "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
       "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
       "4           5.0          3.6           1.4          0.2  Iris-setosa"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# define column names\n",
    "names = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'class']\n",
    "\n",
    "# loading training data\n",
    "\n",
    "path = '/Users/mundanemohit/Google Drive/My Work/MSc. Data Analytics/WiSe 18/3101 Machine Learning/Excercises/Excercise 3'\n",
    "os.chdir(path)\n",
    "filename = 'iris.data'\n",
    "irisDF = pd.read_csv(filename)\n",
    "irisDF.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1: Implement K-Nearest Neighbor (KNN) (10 Points)\n",
    "Your task is to implement KNN algorithm. To implement KNN you have to:\n",
    "+ **Split data into a train and a test split (70% and 30% respectively).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris Dataset ----> Train Set: 105     Test Set:  45\n"
     ]
    }
   ],
   "source": [
    "# create design matrix X and target vector y\n",
    "X = np.array(irisDF.ix[:, 0:4]) \t# end index is exclusive\n",
    "y = np.array(irisDF['class ']) \t# another way of indexing a pandas df\n",
    "\n",
    "# split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=123)\n",
    "\n",
    "print(\"Iris Dataset ----> Train Set:\", len(X_train), \"    Test Set: \", len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **Implement a similarity (or a distance) measure. To begin with you can implement the Euclidean Distance**\n",
    "\n",
    "For each point in the test set, we will calculate it's distance from each point in the training set and add it to a vector.\n",
    "\n",
    "+ **Implement a function that returns top K Nearest Neighbors for a given query (data point).**\n",
    "\n",
    "For each point in the test set, the vector is sorted and top K points are selected as nearest neighbour.\n",
    "\n",
    "+ **You should provide the prediction for a given query (for a classification task you can use majority voting and for a regression you can use mean).**\n",
    "\n",
    "Since IRIS is a classification dataset, we take the most common neighbour as the final prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X_train, y_train, x_test, k):\n",
    "    # create list for distances and targets\n",
    "    distances = []\n",
    "    targets = []\n",
    "\n",
    "    for i in range(len(X_train)):\n",
    "        # first we compute the euclidean distance\n",
    "        distance = np.sqrt(np.sum(np.square(x_test - X_train[i, :])))\n",
    "        # add it to list of distances\n",
    "        distances.append([distance, i])\n",
    "\n",
    "    # sort the list\n",
    "    distances = sorted(distances)\n",
    "\n",
    "    # make a list of the k neighbors' targets\n",
    "    for i in range(k):\n",
    "        index = distances[i][1]\n",
    "        targets.append(y_train[index])\n",
    "\n",
    "    # return most common target\n",
    "    return Counter(targets).most_common(1)[0][0]\n",
    "\n",
    "def kNearestNeighbor(X_train, y_train, X_test, k):\n",
    "    predictions = []\n",
    "    \n",
    "    # loop over all observations\n",
    "    for i in range(len(X_test)):\n",
    "        predictions.append(predict(X_train, y_train, X_test[i, :], k))\n",
    "    \n",
    "    return np.asarray(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **Measure the quality of your prediction. [Hint: You have to choose a quality criterion according to the task you are solving i.e. a regression or a classification task Defend your choice].**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The accuracy of our classifier is 95.555556%\n"
     ]
    }
   ],
   "source": [
    "# making our predictions for k = 3\n",
    "ytest_hat = kNearestNeighbor(X_train, y_train, X_test, k = 3)\n",
    "accuracy = accuracy_score(y_test, ytest_hat) * 100\n",
    "print('\\nThe accuracy of our classifier is %2f%%' % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we used a simple accuracy score where,\n",
    "\n",
    "$$Accuracy = \\frac{correct-classifications}{total-observations}$$\n",
    "\n",
    "We started with k = 3 and got a 95.56% accuracy on the test set which is pretty good given the small size of the dataset. This shows that the Iris dataset is highly homogenous in a multidimensional setting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2: Optimize and Compare KNN algorithm. (10 Points)\n",
    "### Part A: Determine Optimal Value of K in KNN algorithm. In this exercise you have to provide the optimal value of K for given datasets.\n",
    "**1. How you can choose value of K for KNN. Give a criterion to choose an optimal value of K**\n",
    "\n",
    "We can use *k-folds cross-validation with Grid-Search* technique to tune our hyperparameter K. \n",
    "\n",
    "**2. Implement the criterion for choosing the optimal value of K.**\n",
    "\n",
    "+ We will divide our training set into k-folds (where k is different from K) \n",
    "+ For each value of k:\n",
    "    + Use k-1 folds for training\n",
    "    + Run the model on the last fold (validation set)\n",
    "    + Calculate the accuracy score\n",
    "    + Finally, average all the scores\n",
    "\n",
    "The value of K which yeilds the highest accuracy (or lowest error) is the optimal value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def kfold_Cross_Val(X, y, K, CV_splits = 10):\n",
    "    # Define the split - into 10 folds by default\n",
    "    kf = KFold(CV_splits) \n",
    "\n",
    "    fold_accuracy = []\n",
    "    # For each fold\n",
    "    for train_index, val_index in kf.split(X):\n",
    "        # Create training and validation sets\n",
    "        X_train_CV, X_val_CV = X[train_index], X[val_index]\n",
    "        y_train_CV, y_val_CV = y[train_index], y[val_index]\n",
    "        # Make prediction on validation set\n",
    "        yval_hat_CV = kNearestNeighbor(X_train_CV, y_train_CV, X_val_CV, k = K)\n",
    "        # Calculate accuracy\n",
    "        fold_accuracy.append(accuracy_score(y_val_CV, yval_hat_CV))        \n",
    "    # Average accuracy over all folds \n",
    "    return np.mean(fold_accuracy)\n",
    "    \n",
    "# creating list of K for KNN Grid-search\n",
    "neighbors = list(range(1,20))  \n",
    "\n",
    "# empty list that will hold cv scores\n",
    "cv_scores = []\n",
    "\n",
    "# For each K-value\n",
    "for K in neighbors:\n",
    "    # Get average accuracy over all folds\n",
    "    accuracy = kfold_Cross_Val(X_train, y_train, K)\n",
    "    cv_scores.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal number of neighbors is 10\n"
     ]
    }
   ],
   "source": [
    "# changing to misclassification error\n",
    "MSE = [1 - x for x in cv_scores]\n",
    "\n",
    "# determining best K\n",
    "optimal_k = neighbors[MSE.index(min(MSE))]\n",
    "print(\"The optimal number of neighbors is %d\" % optimal_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The accuracy of our classifier is 97.777778%\n"
     ]
    }
   ],
   "source": [
    "# making our predictions on k = 10\n",
    "ytest_hat = kNearestNeighbor(X_train, y_train, X_test, k = optimal_k)\n",
    "accuracy = accuracy_score(y_test, ytest_hat) * 100\n",
    "print('\\nThe accuracy of our classifier is %2f%%' % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So our accuracy has improved from 95.56% (k = 3) to 97.78% (k = 10) !\n",
    "\n",
    "**3. Experimentally, give evidence that your chosen value is better than other values of K. [Hint: run your experiment with different values of K and plot the error measure for each value].**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a16c5b7b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot misclassification error vs k\n",
    "plt.plot(neighbors, MSE)\n",
    "plt.xlabel('Number of Neighbors K')\n",
    "plt.ylabel('Misclassification Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can see that the error is least when k = 10 and 12. \n",
    "\n",
    "### Part B: Compare KNN algorithm with Tree based method. In this task you are allowed to use scikit learn. In particular you have to use Nearest Neighbor and Decision Tree implementation provided by scikit learn.\n",
    "\n",
    "**1. You should be able to use Nearest Neighbor and Decision Tree provided by scikit learn to solve classification task for two datasets.**\n",
    "\n",
    "**2. You have to provide the optimal hyperparameters for both the methods. [Hint: use Grid Search and cross validation and present results for them to support your solution].**\n",
    "\n",
    "**3. Present the comparison of the two methods using evaluation results on test datasets. [Hint: Better to use cross validation to ascertain your results]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-value 1 CROSS-VALIDATION SCORE:  0.9700000000000001\n",
      "K-value 2 CROSS-VALIDATION SCORE:  0.9609090909090909\n",
      "K-value 3 CROSS-VALIDATION SCORE:  0.9609090909090909\n",
      "K-value 4 CROSS-VALIDATION SCORE:  0.970909090909091\n",
      "K-value 5 CROSS-VALIDATION SCORE:  0.9800000000000001\n",
      "K-value 6 CROSS-VALIDATION SCORE:  0.97\n",
      "K-value 7 CROSS-VALIDATION SCORE:  0.97\n",
      "K-value 8 CROSS-VALIDATION SCORE:  0.97\n",
      "K-value 9 CROSS-VALIDATION SCORE:  0.97\n",
      "K-value 10 CROSS-VALIDATION SCORE:  0.97\n",
      "K-value 11 CROSS-VALIDATION SCORE:  0.9800000000000001\n",
      "K-value 12 CROSS-VALIDATION SCORE:  0.97\n",
      "K-value 13 CROSS-VALIDATION SCORE:  0.9700000000000001\n",
      "K-value 14 CROSS-VALIDATION SCORE:  0.96\n",
      "K-value 15 CROSS-VALIDATION SCORE:  0.95\n",
      "K-value 16 CROSS-VALIDATION SCORE:  0.96\n",
      "K-value 17 CROSS-VALIDATION SCORE:  0.95\n",
      "K-value 18 CROSS-VALIDATION SCORE:  0.95\n",
      "K-value 19 CROSS-VALIDATION SCORE:  0.95\n",
      "\n",
      "The optimal number of neighbors is 5\n",
      "\n",
      "The accuracy of our classifier on the test set is 97.777778%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# creating list of K for KNN \n",
    "neighbors = list(range(1,20))\n",
    "\n",
    "# empty list that will hold cv scores\n",
    "cv_scores = []\n",
    "\n",
    "# perform 10-fold cross validation\n",
    "for k in neighbors:\n",
    "    # Build model\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    # Get validation score for each model\n",
    "    scores = cross_val_score(knn, X_train, y_train, cv=10, scoring='accuracy')\n",
    "    # Get mean score for each k\n",
    "    print('K-value', k, 'CROSS-VALIDATION SCORE: ', scores.mean())\n",
    "    cv_scores.append(scores.mean())\n",
    "\n",
    "optimal_k = neighbors[cv_scores.index(max(cv_scores))]\n",
    "print(\"\\nThe optimal number of neighbors is %d\" % optimal_k)\n",
    "\n",
    "# making our predictions on optimal k\n",
    "ytest_hat = kNearestNeighbor(X_train, y_train, X_test, k = optimal_k)\n",
    "accuracy = accuracy_score(y_test, ytest_hat) * 100\n",
    "print('\\nThe accuracy of our classifier on the test set is %2f%%' % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the Cross-Validation inbuilt KNN Classifier in sklearn, we find that the optimal number of neighbors is 5. The classifier accuracy of 97.78% which is the best accuracy achieved from the previous results.\n",
    "\n",
    "Let's now build a tree based classifier with **tree-depth** and **minimum split size** as our hyper parameters. Since our test set comprises only of 45 values, we will keep the depth between 2 & 6 and split size between 2 and 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEPTH: 2 MIN_SAMPLES:  2 CROSS-VALIDATION SCORE:  0.9309090909090909\n",
      "DEPTH: 2 MIN_SAMPLES:  3 CROSS-VALIDATION SCORE:  0.9309090909090909\n",
      "DEPTH: 2 MIN_SAMPLES:  4 CROSS-VALIDATION SCORE:  0.9309090909090909\n",
      "DEPTH: 2 MIN_SAMPLES:  5 CROSS-VALIDATION SCORE:  0.9109090909090909\n",
      "DEPTH: 2 MIN_SAMPLES:  6 CROSS-VALIDATION SCORE:  0.9309090909090909\n",
      "DEPTH: 2 MIN_SAMPLES:  7 CROSS-VALIDATION SCORE:  0.9309090909090909\n",
      "DEPTH: 2 MIN_SAMPLES:  8 CROSS-VALIDATION SCORE:  0.9309090909090909\n",
      "DEPTH: 2 MIN_SAMPLES:  9 CROSS-VALIDATION SCORE:  0.9109090909090909\n",
      "DEPTH: 3 MIN_SAMPLES:  2 CROSS-VALIDATION SCORE:  0.95\n",
      "DEPTH: 3 MIN_SAMPLES:  3 CROSS-VALIDATION SCORE:  0.9400000000000001\n",
      "DEPTH: 3 MIN_SAMPLES:  4 CROSS-VALIDATION SCORE:  0.95\n",
      "DEPTH: 3 MIN_SAMPLES:  5 CROSS-VALIDATION SCORE:  0.9400000000000001\n",
      "DEPTH: 3 MIN_SAMPLES:  6 CROSS-VALIDATION SCORE:  0.95\n",
      "DEPTH: 3 MIN_SAMPLES:  7 CROSS-VALIDATION SCORE:  0.95\n",
      "DEPTH: 3 MIN_SAMPLES:  8 CROSS-VALIDATION SCORE:  0.95\n",
      "DEPTH: 3 MIN_SAMPLES:  9 CROSS-VALIDATION SCORE:  0.95\n",
      "DEPTH: 4 MIN_SAMPLES:  2 CROSS-VALIDATION SCORE:  0.9600000000000002\n",
      "DEPTH: 4 MIN_SAMPLES:  3 CROSS-VALIDATION SCORE:  0.9400000000000001\n",
      "DEPTH: 4 MIN_SAMPLES:  4 CROSS-VALIDATION SCORE:  0.95\n",
      "DEPTH: 4 MIN_SAMPLES:  5 CROSS-VALIDATION SCORE:  0.9600000000000002\n",
      "DEPTH: 4 MIN_SAMPLES:  6 CROSS-VALIDATION SCORE:  0.95\n",
      "DEPTH: 4 MIN_SAMPLES:  7 CROSS-VALIDATION SCORE:  0.9400000000000001\n",
      "DEPTH: 4 MIN_SAMPLES:  8 CROSS-VALIDATION SCORE:  0.9600000000000002\n",
      "DEPTH: 4 MIN_SAMPLES:  9 CROSS-VALIDATION SCORE:  0.9400000000000001\n",
      "DEPTH: 5 MIN_SAMPLES:  2 CROSS-VALIDATION SCORE:  0.9600000000000002\n",
      "DEPTH: 5 MIN_SAMPLES:  3 CROSS-VALIDATION SCORE:  0.9400000000000001\n",
      "DEPTH: 5 MIN_SAMPLES:  4 CROSS-VALIDATION SCORE:  0.9600000000000002\n",
      "DEPTH: 5 MIN_SAMPLES:  5 CROSS-VALIDATION SCORE:  0.95\n",
      "DEPTH: 5 MIN_SAMPLES:  6 CROSS-VALIDATION SCORE:  0.95\n",
      "DEPTH: 5 MIN_SAMPLES:  7 CROSS-VALIDATION SCORE:  0.95\n",
      "DEPTH: 5 MIN_SAMPLES:  8 CROSS-VALIDATION SCORE:  0.95\n",
      "DEPTH: 5 MIN_SAMPLES:  9 CROSS-VALIDATION SCORE:  0.9400000000000001\n",
      "DEPTH: 6 MIN_SAMPLES:  2 CROSS-VALIDATION SCORE:  0.9600000000000002\n",
      "DEPTH: 6 MIN_SAMPLES:  3 CROSS-VALIDATION SCORE:  0.9600000000000002\n",
      "DEPTH: 6 MIN_SAMPLES:  4 CROSS-VALIDATION SCORE:  0.95\n",
      "DEPTH: 6 MIN_SAMPLES:  5 CROSS-VALIDATION SCORE:  0.9400000000000001\n",
      "DEPTH: 6 MIN_SAMPLES:  6 CROSS-VALIDATION SCORE:  0.95\n",
      "DEPTH: 6 MIN_SAMPLES:  7 CROSS-VALIDATION SCORE:  0.9600000000000002\n",
      "DEPTH: 6 MIN_SAMPLES:  8 CROSS-VALIDATION SCORE:  0.9400000000000001\n",
      "DEPTH: 6 MIN_SAMPLES:  9 CROSS-VALIDATION SCORE:  0.9400000000000001\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "depth = list(range(2,7))\n",
    "samples = list(range(2,10))\n",
    "\n",
    "# empty list that will hold cv scores\n",
    "cv_scores = []\n",
    "\n",
    "for d in depth:\n",
    "    for s in samples:\n",
    "        clf = tree.DecisionTreeClassifier(max_depth = d, min_samples_split = s)\n",
    "        clf = clf.fit(X_train, y_train)\n",
    "        scores = cross_val_score(clf, X_train, y_train, cv=10, scoring='accuracy')\n",
    "        # Get mean score for each combination\n",
    "        print('DEPTH:', d, 'MIN_SAMPLES: ', s, 'CROSS-VALIDATION SCORE: ', scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ We see that depth of 3-5 and split size of 5-7 yeilds best results. \n",
    "+ Let's use (4, 5) as our combination for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The accuracy of our classifier  on the test set is 93.333333%\n"
     ]
    }
   ],
   "source": [
    "clf = tree.DecisionTreeClassifier(max_depth = 4, min_samples_split = 5)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "ytest_hat = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, ytest_hat) * 100\n",
    "print('\\nThe accuracy of our classifier  on the test set is %2f%%' % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running cross-validation to find best set of hyper-parameters for our KNN and Tree models respectively, we conclude that the KNN model had an overall higher accuracy than the tree based model. In a **KNN model** we tried to cluster similar (smaller distance) occurances together in a multidimensional space. This is a computation heavy task since it requires us to calculate distance between each observation. Therefore, for 100 observations we need to calculate 10,000 distance values. However, this also means that KNN can find the best possible solution to a problem since it has all the information before it starts the classification process.\n",
    "\n",
    "A **tree based model** on the other hand, tries to maximize it's information gain at every step without knowing the final outcome. Therefore, it does not have the vision of KNN but is computationally much faster. This is useful when you have large amounts of data and do not require extremely high levels of accuracy.\n",
    "\n",
    "Generally, in larger and noisier datasets, a tree model would be preferable to gain a general insight and learn segregation rules. However, in our case with 150 observations, KNN outperforms tree-based model because of the scarcity and homogenity of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### References:\n",
    "\n",
    "+ Complete Guide to KNN with application in Python & R - https://kevinzakka.github.io/2016/07/13/k-nearest-neighbor/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
